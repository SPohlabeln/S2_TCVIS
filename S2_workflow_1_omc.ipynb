{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d927483d",
   "metadata": {},
   "source": [
    "## omc (downloading masked images per year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# CONFIG\n",
    "# =========================================\n",
    "YEARS            = list(range(2017, 2021))\n",
    "MONTH_START_END  = (\"07-01\", \"08-31\")\n",
    "GRID             = \"MGRS-05WMU\"\n",
    "MAX_CLOUD_COVER  = 70\n",
    "BBOX_LL          = (-153.5, 70.5, -153, 71)\n",
    "OUT_DIR          = \"CDSE_scenes_masked/coverage70\"\n",
    "\n",
    "import os\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]     = \"C364NPCJK6JQ64OIMZJR\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"...\"   # fill in securely\n",
    "os.environ[\"AWS_REGION\"]            = \"us-east-1\"\n",
    "os.environ[\"AWS_S3_ENDPOINT\"]       = \"eodata.dataspace.copernicus.eu\"\n",
    "os.environ[\"AWS_VIRTUAL_HOSTING\"]   = \"FALSE\"\n",
    "\n",
    "# =========================================\n",
    "# IMPORTS\n",
    "# =========================================\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from pyproj import Transformer\n",
    "import rasterio as rio\n",
    "from rasterio.enums import Resampling\n",
    "from pystac_client import Client\n",
    "from pystac import Item\n",
    "from omnicloudmask import predict_from_array\n",
    "from shapely.geometry import shape, box, mapping\n",
    "from shapely.ops import transform as shapely_transform\n",
    "# =========================================\n",
    "# HELPERS\n",
    "# =========================================\n",
    "def search_s2_stac(start_date: str, end_date: str, grid: str, max_cloud_cover: int = 100) -> list[Item]:\n",
    "    cat = Client.open(\"https://stac.dataspace.copernicus.eu/v1/\")\n",
    "    search = cat.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        datetime=f\"{start_date}/{end_date}\",\n",
    "        query={\"eo:cloud_cover\": {\"lte\": max_cloud_cover}, \"grid:code\": {\"eq\": grid}},\n",
    "    )\n",
    "    items = list(search.items())\n",
    "    print(f\"  üîé Found {len(items)} items\")\n",
    "    return items\n",
    "\n",
    "def prefer_s3_assets(items):\n",
    "    out = []\n",
    "    for it in items:\n",
    "        it = it.clone()\n",
    "        for a in it.assets.values():\n",
    "            s3_href = None\n",
    "            extra = (getattr(a, \"extra_fields\", None) or {})\n",
    "            alt = extra.get(\"alternate\") or extra.get(\"alternates\")\n",
    "            if isinstance(alt, dict):\n",
    "                s3_href = (alt.get(\"s3\") or alt.get(\"S3\") or {}).get(\"href\")\n",
    "            elif isinstance(alt, list):\n",
    "                for d in alt:\n",
    "                    href = d.get(\"href\")\n",
    "                    if href and href.startswith(\"s3://\"):\n",
    "                        s3_href = href\n",
    "                        break\n",
    "            if s3_href:\n",
    "                a.href = s3_href\n",
    "        out.append(it)\n",
    "    return out\n",
    "\n",
    "def detect_epsg_and_bounds(items, bbox_ll_override=None):\n",
    "    if not items:\n",
    "        raise ValueError(\"No items\")\n",
    "\n",
    "    if bbox_ll_override is None:\n",
    "        bbs = [it.bbox for it in items]\n",
    "        minx = min(b[0] for b in bbs)\n",
    "        miny = min(b[1] for b in bbs)\n",
    "        maxx = max(b[2] for b in bbs)\n",
    "        maxy = max(b[3] for b in bbs)\n",
    "        bbox_ll = (minx, miny, maxx, maxy)\n",
    "    else:\n",
    "        bbox_ll = bbox_ll_override\n",
    "\n",
    "    epsg = None\n",
    "    for it in items:\n",
    "        if \"proj:epsg\" in it.properties:\n",
    "            epsg = int(it.properties[\"proj:epsg\"])\n",
    "            break\n",
    "    if epsg is None:\n",
    "        lon = (bbox_ll[0] + bbox_ll[2]) / 2.0\n",
    "        lat = (bbox_ll[1] + bbox_ll[3]) / 2.0\n",
    "        zone = int(math.floor((lon + 180) / 6) + 1)\n",
    "        epsg = 32600 + zone if lat >= 0 else 32700 + zone\n",
    "\n",
    "    tx = Transformer.from_crs(\"EPSG:4326\", f\"EPSG:{epsg}\", always_xy=True)\n",
    "    x1, y1 = tx.transform(bbox_ll[0], bbox_ll[1])\n",
    "    x2, y2 = tx.transform(bbox_ll[2], bbox_ll[3])\n",
    "    bounds_proj = (min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2))\n",
    "    return epsg, bbox_ll, bounds_proj\n",
    "\n",
    "def projected_intersection_ratio(item_geom, aoi_bounds, epsg_out):\n",
    "    # Transform AOI bbox (in lon/lat) to projected coords\n",
    "    tx = Transformer.from_crs(\"EPSG:4326\", f\"EPSG:{epsg_out}\", always_xy=True)\n",
    "    aoi_proj = shapely_transform(tx.transform, box(*aoi_bounds))\n",
    "\n",
    "    # Get item's footprint and project it too\n",
    "    geom = shape(item_geom)\n",
    "    geom_proj = shapely_transform(tx.transform, geom)\n",
    "\n",
    "    inter = geom_proj.intersection(aoi_proj)\n",
    "\n",
    "    if inter.is_empty:\n",
    "        return 0.0\n",
    "\n",
    "    return inter.area / aoi_proj.area\n",
    "\n",
    "def rasterio_env():\n",
    "    return rio.Env(\n",
    "        AWS_S3_ENDPOINT=os.environ[\"AWS_S3_ENDPOINT\"],\n",
    "        AWS_REGION=os.environ[\"AWS_REGION\"],\n",
    "        AWS_VIRTUAL_HOSTING=os.environ[\"AWS_VIRTUAL_HOSTING\"],\n",
    "        GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
    "        CPL_VSIL_CURL_ALLOWED_EXTENSIONS=\"tif,gtiff,jp2,xml\"\n",
    "    )\n",
    "\n",
    "# =========================================\n",
    "# PROCESS\n",
    "# =========================================\n",
    "BAND_ORDER  = [\"B02_10m\",\"B03_10m\",\"B04_10m\",\"B08_10m\",\"B11_20m\",\"B12_20m\"]\n",
    "BAND_LABELS = [\"Blue\",\"Green\",\"Red\",\"NIR\",\"SWIR1\",\"SWIR2\"]\n",
    "\n",
    "def process_year(year: int, grid: str, max_cloud: int, bbox_ll):\n",
    "    print(f\"\\n==== Year {year} | grid={grid} | clouds‚â§{max_cloud}% ====\")\n",
    "    start_date = f\"{year}-{MONTH_START_END[0]}\"\n",
    "    end_date   = f\"{year}-{MONTH_START_END[1]}\"\n",
    "\n",
    "    items = search_s2_stac(start_date, end_date, grid, max_cloud_cover=max_cloud)\n",
    "    if not items:\n",
    "        print(\"  ‚ö†Ô∏è No items for this year.\")\n",
    "        return 0\n",
    "\n",
    "    items_s3 = prefer_s3_assets(items)\n",
    "    epsg_out, bbox_ll_used, bounds_out = detect_epsg_and_bounds(items, bbox_ll_override=bbox_ll)\n",
    "    print(f\"  EPSG={epsg_out} | bounds_proj={tuple(round(v,2) for v in bounds_out)}\")\n",
    "\n",
    "    bands_10m = [b for b in BAND_ORDER if b.endswith(\"10m\")]\n",
    "    bands_20m = [b for b in BAND_ORDER if b.endswith(\"20m\")]\n",
    "\n",
    "    out_dir = Path(OUT_DIR) / str(year)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    n_ok = 0\n",
    "\n",
    "    with rasterio_env():\n",
    "        for it_s3, it_orig in zip(items_s3, items):\n",
    "            scene_date = it_orig.properties.get(\"datetime\", \"\").split(\"T\")[0]\n",
    "            print(f\"\\n‚Üí Scene {it_orig.id} ({scene_date})\")\n",
    "            # ------------------------------------------------\n",
    "            # AOI intersection check (BEFORE loading bands)\n",
    "            # ------------------------------------------------\n",
    "            coverage_ratio = projected_intersection_ratio(\n",
    "                item_geom = it_orig.geometry,\n",
    "                aoi_bounds = bbox_ll,      # in lon/lat!\n",
    "                epsg_out = epsg_out        # detected for the tile\n",
    "            )\n",
    "\n",
    "            print(f\"   ‚ÑπÔ∏è AOI intersection coverage: {coverage_ratio:.2%}\")\n",
    "\n",
    "            if coverage_ratio < 0.4:  # Example: require 5% coverage\n",
    "                print(\"   ‚ö†Ô∏è Scene skipped due to low AOI coverage.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                ref = None\n",
    "                pieces = []\n",
    "\n",
    "                for bname in bands_10m:\n",
    "                    if bname not in it_s3.assets:\n",
    "                        continue\n",
    "                    href = it_s3.assets[bname].href\n",
    "                    da = rioxarray.open_rasterio(href, masked=True).squeeze(\"band\", drop=True)\n",
    "                    if da.rio.crs is None:\n",
    "                        da = da.rio.write_crs(f\"EPSG:{epsg_out}\")\n",
    "                    da = da.rio.clip_box(*bounds_out)\n",
    "                    if ref is None:\n",
    "                        ref = da\n",
    "                    pieces.append(da.expand_dims(\"band\"))\n",
    "\n",
    "                for bname in bands_20m:\n",
    "                    if bname not in it_s3.assets:\n",
    "                        continue\n",
    "                    href = it_s3.assets[bname].href\n",
    "                    da20 = rioxarray.open_rasterio(href, masked=True).squeeze(\"band\", drop=True)\n",
    "                    if da20.rio.crs is None:\n",
    "                        da20 = da20.rio.write_crs(f\"EPSG:{epsg_out}\")\n",
    "                    da20 = da20.rio.clip_box(*bounds_out)\n",
    "                    da20u = da20.rio.reproject_match(ref, resampling=Resampling.bilinear)\n",
    "                    pieces.append(da20u.expand_dims(\"band\"))\n",
    "\n",
    "                if not pieces:\n",
    "                    print(\"   ‚ö†Ô∏è No usable bands.\")\n",
    "                    continue\n",
    "\n",
    "                scene = xr.concat(pieces, dim=\"band\")\n",
    "                scene = scene.assign_coords(band=BAND_LABELS)\n",
    "                if scene.rio.crs is None:\n",
    "                    scene = scene.rio.write_crs(f\"EPSG:{epsg_out}\")\n",
    "\n",
    "                # MASKING\n",
    "                red   = scene.sel(band=\"Red\").values\n",
    "                green = scene.sel(band=\"Green\").values\n",
    "                nir   = scene.sel(band=\"NIR\").values\n",
    "                input_array = np.stack([red, green, nir], axis=0)\n",
    "\n",
    "                try:\n",
    "                    pred_mask = predict_from_array(input_array)\n",
    "\n",
    "                    # Handle shape (1, H, W) or (3, H, W)\n",
    "                    if pred_mask.ndim == 3:\n",
    "                        if pred_mask.shape[0] == 1:\n",
    "                            pred_mask = pred_mask[0]\n",
    "                        elif pred_mask.shape[0] == 3:\n",
    "                            pred_mask = pred_mask[1]  # assume class 1 = cloud\n",
    "\n",
    "                    # Ensure mask shape matches (y, x)\n",
    "                    if pred_mask.shape != (scene.sizes[\"y\"], scene.sizes[\"x\"]):\n",
    "                        raise ValueError(f\"‚ùå Mask shape {pred_mask.shape} does not match scene shape {(scene.sizes['y'], scene.sizes['x'])}\")\n",
    "\n",
    "                    # Keep only pixels where class == 0\n",
    "                    mask_keep = pred_mask == 0\n",
    "\n",
    "                    mask_da = xr.DataArray(\n",
    "                        mask_keep,\n",
    "                        dims=(\"y\", \"x\"),\n",
    "                        coords={\"y\": scene.coords[\"y\"], \"x\": scene.coords[\"x\"]}\n",
    "                    )\n",
    "\n",
    "                    scene = scene.where(mask_da)\n",
    "                    print(\"   ‚úî Cloud mask applied.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"   ‚ö†Ô∏è Cloud mask failed:\", e)\n",
    "\n",
    "                scene_u16 = (\n",
    "                    scene.fillna(0)\n",
    "                    .clip(0, 10000)\n",
    "                    .astype(\"uint16\")\n",
    "                    .rio.write_nodata(0)\n",
    "                    .rio.write_crs(f\"EPSG:{epsg_out}\")\n",
    "                )\n",
    "\n",
    "                out_path = out_dir / f\"{it_orig.id}_{scene_date}_masked.tif\"\n",
    "                print(\"   üíæ Saving ‚Üí\", out_path)\n",
    "                scene_u16.transpose(\"band\", \"y\", \"x\").rio.to_raster(\n",
    "                    out_path,\n",
    "                    driver=\"GTiff\",\n",
    "                    compress=\"deflate\",\n",
    "                    tiled=True,\n",
    "                    predictor=2,\n",
    "                    BIGTIFF=\"IF_SAFER\",\n",
    "                    blockxsize=512,\n",
    "                    blockysize=512,\n",
    "                )\n",
    "                n_ok += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"   ‚ùå Scene failed:\", e)\n",
    "\n",
    "    return n_ok\n",
    "\n",
    "# =========================================\n",
    "# RUN ALL YEARS\n",
    "# =========================================\n",
    "all_counts = {}\n",
    "for yr in YEARS:\n",
    "    n = process_year(yr, GRID, MAX_CLOUD_COVER, bbox_ll=BBOX_LL)\n",
    "    all_counts[yr] = n\n",
    "\n",
    "print(\"\\n‚úÖ Done. Scenes written per year:\")\n",
    "for yr, n in all_counts.items():\n",
    "    print(f\" ‚Ä¢ {yr}: {n} scenes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546059de",
   "metadata": {},
   "source": [
    "## Stack to median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da937c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------\n",
    "# CONFIG\n",
    "# --------------------------------------------\n",
    "TIF_DIR     = Path(\"CDSE_scenes_masked/coverage70/2025\")  # Folder with the TIFFs\n",
    "OUT_PATH    = Path(\"CDSE_2025_median_70.tif\")   # Output file\n",
    "BAND_LABELS = [\"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\"]  # Optional\n",
    "\n",
    "# --------------------------------------------\n",
    "# LOAD TIFFS\n",
    "# --------------------------------------------\n",
    "tif_files = sorted(TIF_DIR.glob(\"*.tif\"))\n",
    "print(f\"üóÇ Found {len(tif_files)} TIFFs\")\n",
    "\n",
    "scenes = []\n",
    "\n",
    "for f in tif_files:\n",
    "    try:\n",
    "        ds = rioxarray.open_rasterio(f, masked=True)  # shape: (band, y, x)\n",
    "        if \"band\" not in ds.coords:\n",
    "            ds = ds.assign_coords(band=range(1, ds.sizes[\"band\"] + 1))\n",
    "\n",
    "        # Optionally set band names\n",
    "        if len(BAND_LABELS) == ds.sizes[\"band\"]:\n",
    "            ds = ds.assign_coords(band=BAND_LABELS)\n",
    "\n",
    "        scenes.append(ds.expand_dims(time=[f.name]))  # add time dimension\n",
    "        print(f\"   ‚úì Loaded {f.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Failed to load {f.name}: {e}\")\n",
    "\n",
    "if not scenes:\n",
    "    raise RuntimeError(\"‚ùå No scenes could be loaded.\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# STACK + MEDIAN\n",
    "# --------------------------------------------\n",
    "stack = xr.concat(scenes, dim=\"time\")\n",
    "print(\"üìä Stack shape:\", stack.shape)\n",
    "\n",
    "median_img = stack.median(dim=\"time\", skipna=True)\n",
    "\n",
    "# --------------------------------------------\n",
    "# SAVE MEDIAN STACK\n",
    "# --------------------------------------------\n",
    "median_img_u16 = (\n",
    "    median_img\n",
    "    .clip(0, 10000)\n",
    "    .fillna(0)\n",
    "    .astype(\"uint16\")\n",
    "    .rio.write_nodata(0)\n",
    ")\n",
    "\n",
    "print(f\"üíæ Saving median image to {OUT_PATH}\")\n",
    "median_img_u16.rio.to_raster(\n",
    "    OUT_PATH,\n",
    "    driver=\"GTiff\",\n",
    "    compress=\"deflate\",\n",
    "    tiled=True,\n",
    "    predictor=2,\n",
    "    BIGTIFF=\"IF_SAFER\",\n",
    "    blockxsize=512,\n",
    "    blockysize=512,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73515b1b",
   "metadata": {},
   "source": [
    "## Calculating TC images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === tasseled_cap_mosaic_generation.py ===\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from dask.diagnostics import ProgressBar\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*coordinate precision.*\")\n",
    "\n",
    "median_dir = Path(\"omc_medians_70\")       \n",
    "tc_dir = Path(\"omc_tc_70\")                      \n",
    "tc_dir.mkdir(exist_ok=True)\n",
    "years = list(range(2025, 2026))\n",
    "\n",
    "# Sentinel-2 Tasseled Cap coefficients \n",
    "coeffs = {\n",
    "    \"tcb\": dict(Blue=0.3037, Green=0.2793, Red=0.4743, NIR=0.5585, SWIR1=0.5082, SWIR2=0.1863),\n",
    "    \"tcg\": dict(Blue=-0.2848, Green=-0.2435, Red=-0.5436, NIR=0.7243, SWIR1=0.0840, SWIR2=-0.1800),\n",
    "    \"tcw\": dict(Blue=0.1509, Green=0.1973, Red=0.3279, NIR=0.3406, SWIR1=-0.7112, SWIR2=-0.4572),\n",
    "}\n",
    "\n",
    "for year in years:\n",
    "    in_file = median_dir / f\"CDSE_{year}_median_70.tif\"\n",
    "    out_file = tc_dir / f\"tc_CDSE_{year}_median_70.tif\"\n",
    "\n",
    "    if not in_file.exists():\n",
    "        print(f\"‚ùå Missing median mosaic for {year}\")\n",
    "        continue\n",
    "    if out_file.exists():\n",
    "        print(f\"‚è≠Ô∏è Already exists, skipping {out_file}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‚úÖ Loading: {in_file}\")\n",
    "    # Important: masked=True makes rioxarray treat nodata (0) as NaN\n",
    "    da = rioxarray.open_rasterio(in_file, chunks={\"x\": 1024, \"y\": 1024}, masked=True)\n",
    "\n",
    "    # assign band names, convert reflectance to 0‚Äì1\n",
    "    da = da.assign_coords(band=[\"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\"]).astype(\"float32\") / 10000.0          # not needed - 0.1 \n",
    "\n",
    "    # Ensure true zeros are NaN (in case old medians used fillna(0))\n",
    "    da = da.where(da != 0)\n",
    "\n",
    "    # Split bands\n",
    "    blue, green, red, nir, swir1, swir2 = da.sel(band=[\"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\"])\n",
    "\n",
    "    def tc(c):\n",
    "        return (c[\"Blue\"]*blue + c[\"Green\"]*green + c[\"Red\"]*red +\n",
    "                c[\"NIR\"]*nir + c[\"SWIR1\"]*swir1 + c[\"SWIR2\"]*swir2)\n",
    "\n",
    "    # Compute tasseled cap \n",
    "    tcb = tc(coeffs[\"tcb\"])\n",
    "    tcg = tc(coeffs[\"tcg\"])\n",
    "    tcw = tc(coeffs[\"tcw\"])\n",
    "\n",
    "    # Stack tc\n",
    "    tc_stack = xr.concat([tcb, tcg, tcw], dim=\"band\")\n",
    "    tc_stack = tc_stack.assign_coords(band=[\"TCB\", \"TCG\", \"TCW\"])\n",
    "    tc_stack = tc_stack.rio.write_crs(da.rio.crs)\n",
    "\n",
    "    # Ensure NaNs are preserved\n",
    "    tc_stack = tc_stack.astype(\"float32\").rio.write_nodata(np.nan)\n",
    "\n",
    "    print(f\"üíæ Saving tasseled cap mosaic: {out_file}\")\n",
    "    with ProgressBar():\n",
    "        (\n",
    "            tc_stack.compute(scheduler=\"threads\")\n",
    "            .transpose(\"band\", \"y\", \"x\")\n",
    "            .rio.to_raster(\n",
    "                out_file,\n",
    "                driver=\"GTiff\",\n",
    "                tiled=True,\n",
    "                compress=\"deflate\",\n",
    "                BIGTIFF=\"IF_SAFER\",\n",
    "                predictor=3,           \n",
    "                blockxsize=1024,\n",
    "                blockysize=1024,\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ All tasseled cap mosaics saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b02b4e",
   "metadata": {},
   "source": [
    "## Trend Calculation (fixed vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# TREND CALCULATION FOR TC STACKS\n",
    "# =========================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from dask.diagnostics import ProgressBar\n",
    "import dask\n",
    "import logging\n",
    "\n",
    "# -----------------------------------------\n",
    "# CONFIG\n",
    "# -----------------------------------------\n",
    "tc_dir     = Path(\"omc_tc_70\")          # input mosaics\n",
    "trend_dir  = Path(\"omc_trends\")  # output directory\n",
    "trend_dir.mkdir(exist_ok=True)\n",
    "\n",
    "years = list(range(2017, 2026))\n",
    "bands_tc = [\"TCB\", \"TCG\", \"TCW\"]\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1. LOAD ALL TASSELED CAP MOSAICS\n",
    "# -----------------------------------------\n",
    "arrays = []\n",
    "\n",
    "for year in years:\n",
    "    fp = tc_dir / f\"tc_CDSE_{year}_median_70.tif\"\n",
    "    if not fp.exists():\n",
    "        print(f\"‚ùå Missing {fp}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‚úÖ Loading {fp}\")\n",
    "    da = rioxarray.open_rasterio(fp, chunks={\"x\": 1024, \"y\": 1024})\n",
    "\n",
    "    # Assign TC band names\n",
    "    da = da.assign_coords(band=bands_tc)\n",
    "\n",
    "    # Add numeric time coordinate\n",
    "    da = da.expand_dims(time=[np.datetime64(f\"{year}-07-15\")])\n",
    "\n",
    "    arrays.append(da)\n",
    "\n",
    "if not arrays:\n",
    "    raise RuntimeError(\"No tasseled cap mosaics found!\")\n",
    "\n",
    "# Concatenate stack\n",
    "stack = xr.concat(arrays, dim=\"time\").transpose(\"time\", \"band\", \"y\", \"x\")\n",
    "stack = stack.chunk({\"time\": -1, \"x\": 1024, \"y\": 1024})\n",
    "stack.name = \"tc\"\n",
    "\n",
    "print(f\"üß© Stack shape: {stack.shape} (time, band, y, x)\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2. FIX THE TIME AXIS FOR REGRESSION\n",
    "# -----------------------------------------\n",
    "# Convert datetime64 ‚Üí integer years\n",
    "years_numeric = stack[\"time\"].dt.year\n",
    "\n",
    "# Replace time dim with 'year'\n",
    "stack = stack.assign_coords(year=(\"time\", years_numeric.data))\n",
    "stack = stack.swap_dims({\"time\": \"year\"})\n",
    "\n",
    "print(f\"üìÖ Using year values for regression: {list(years_numeric.values)}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3. TREND REGRESSION (PER YEAR)\n",
    "# -----------------------------------------\n",
    "results = []\n",
    "\n",
    "for band in bands_tc:\n",
    "    print(f\"üìà Computing trend for {band}...\")\n",
    "\n",
    "    sub = stack.sel(band=band)\n",
    "\n",
    "    # Fit a first-degree polynomial across the 'year' axis\n",
    "    fit = sub.to_dataset(name=\"tc\").polyfit(dim=\"year\", deg=1)\n",
    "\n",
    "    # Extract slope (degree 1 coefficient)\n",
    "    slope = fit[\"tc_polyfit_coefficients\"].sel(degree=1)\n",
    "\n",
    "    # OPTIONAL ‚Äî\n",
    "    # match GEE visualization intensity (your GEE script did \"*10\")\n",
    "    slope = slope * 10\n",
    "\n",
    "    slope = slope.expand_dims(band=[f\"{band}_slope\"])\n",
    "    results.append(slope)\n",
    "\n",
    "# Combine all slope bands\n",
    "trend = xr.concat(results, dim=\"band\")\n",
    "trend.rio.write_crs(stack.rio.crs, inplace=True)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4. COMPUTE THE ARRAY\n",
    "# -----------------------------------------\n",
    "out_path = trend_dir / \"tc_trend_omc1.tif\"\n",
    "print(f\"üíæ Saving trend raster: {out_path}\")\n",
    "\n",
    "# Threaded Dask scheduler\n",
    "dask.config.set(scheduler=\"threads\")\n",
    "logging.getLogger(\"tornado.application\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"tornado.general\").setLevel(logging.ERROR)\n",
    "\n",
    "with ProgressBar(dt=30.0):  \n",
    "    trend = trend.compute()\n",
    "\n",
    "trend_vis = trend.clip(-0.3, 0.3)\n",
    "trend_vis = ((trend_vis + 0.3) / 0.6 * 255).astype(\"uint8\")\n",
    "trend_vis.transpose(\"band\", \"y\", \"x\").rio.to_raster(\"trend_visual_70_no2024.tif\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5. SAVE TO GEOTIFF\n",
    "# -----------------------------------------\n",
    "trend_vis.transpose(\"band\", \"y\", \"x\").rio.to_raster(\n",
    "    out_path,\n",
    "    driver=\"GTiff\",\n",
    "    tiled=True,\n",
    "    compress=\"deflate\",\n",
    "    BIGTIFF=\"IF_SAFER\",\n",
    "    predictor=2,\n",
    "    blockxsize=1024,\n",
    "    blockysize=1024,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trend image saved successfully.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_omnicloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
