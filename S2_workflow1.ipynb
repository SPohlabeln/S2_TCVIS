{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d927483d",
   "metadata": {},
   "source": [
    "## Creating annual aggregates: AOI specific CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# CONFIG\n",
    "# =========================================\n",
    "YEARS            = list(range(2017, 2018))     \n",
    "MONTH_START_END  = (\"07-01\", \"08-31\")          \n",
    "GRID             = \"MGRS-05WMU\"               # e.g. \"MGRS-05WMN\"\n",
    "MAX_CLOUD_COVER  = 70                          # Broad STAC filter (scene-wide)\n",
    "AOI_CLOUD_THRESH = 0.4                         # AOI cloud filter (20%)\n",
    "BBOX_LL          = (-153.5, 70.5, -153, 71)     # (minx,miny,maxx,maxy)\n",
    "\n",
    "REDUCER          = \"median\"                 # \"median\" or \"quantile\"\n",
    "Q                = 0.25\n",
    "QUANT_METHOD     = \"nearest\"\n",
    "\n",
    "OUT_DIR          = \"CDSE_annual_median_small\"\n",
    "\n",
    "# =========================================\n",
    "# ENV SETUP\n",
    "# =========================================\n",
    "import os\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]     = \"C364NPCJK6JQ64OIMZJR\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"xpoRWkPi2ktOVRavz69FKnDUKjLjv8cmWk6rESO3\"\n",
    "os.environ[\"AWS_REGION\"]            = \"us-east-1\"\n",
    "os.environ[\"AWS_S3_ENDPOINT\"]       = \"eodata.dataspace.copernicus.eu\"\n",
    "os.environ[\"AWS_VIRTUAL_HOSTING\"]   = \"FALSE\"\n",
    "\n",
    "# =========================================\n",
    "# IMPORTS\n",
    "# =========================================\n",
    "from pathlib import Path\n",
    "from pystac_client import Client\n",
    "from pystac import Item\n",
    "import math\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from pyproj import Transformer\n",
    "import rasterio as rio\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "# =========================================\n",
    "# HELPERS\n",
    "# =========================================\n",
    "def search_s2_stac(start_date: str, end_date: str, grid: str, max_cloud_cover: int = 100):\n",
    "    cat = Client.open(\"https://stac.dataspace.copernicus.eu/v1/\")\n",
    "    search = cat.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        datetime=f\"{start_date}/{end_date}\",\n",
    "        query={\"eo:cloud_cover\": {\"lte\": max_cloud_cover}, \"grid:code\": {\"eq\": grid}},\n",
    "    )\n",
    "    items = list(search.items())\n",
    "    print(f\"  üîé Found {len(items)} items\")\n",
    "    return items\n",
    "\n",
    "def prefer_s3_assets(items):\n",
    "    out = []\n",
    "    for it in items:\n",
    "        it = it.clone()\n",
    "        for a in it.assets.values():\n",
    "            s3_href = None\n",
    "            extra = (getattr(a, \"extra_fields\", None) or {})\n",
    "            alt = extra.get(\"alternate\") or extra.get(\"alternates\")\n",
    "            if isinstance(alt, dict):\n",
    "                s3_href = (alt.get(\"s3\") or alt.get(\"S3\") or {}).get(\"href\")\n",
    "            elif isinstance(alt, list):\n",
    "                for d in alt:\n",
    "                    href = d.get(\"href\")\n",
    "                    if href and href.startswith(\"s3://\"):\n",
    "                        s3_href = href; break\n",
    "            if s3_href:\n",
    "                a.href = s3_href\n",
    "        out.append(it)\n",
    "    return out\n",
    "\n",
    "def detect_epsg_and_bounds(items, bbox_ll_override=None):\n",
    "    if not items:\n",
    "        raise ValueError(\"No items passed to detect_epsg_and_bounds\")\n",
    "\n",
    "    if bbox_ll_override is None:\n",
    "        bbs = [it.bbox for it in items]\n",
    "        minx = min(b[0] for b in bbs); miny = min(b[1] for b in bbs)\n",
    "        maxx = max(b[2] for b in bbs); maxy = max(b[3] for b in bbs)\n",
    "        bbox_ll = (minx, miny, maxx, maxy)\n",
    "    else:\n",
    "        bbox_ll = bbox_ll_override\n",
    "\n",
    "    epsg = None\n",
    "    for it in items:\n",
    "        if \"proj:epsg\" in it.properties:\n",
    "            epsg = int(it.properties[\"proj:epsg\"]); break\n",
    "    if epsg is None:\n",
    "        lon, lat = ((bbox_ll[0] + bbox_ll[2]) / 2.0, (bbox_ll[1] + bbox_ll[3]) / 2.0)\n",
    "        zone = int(math.floor((lon + 180) / 6) + 1)\n",
    "        epsg = 32600 + zone if lat >= 0 else 32700 + zone\n",
    "\n",
    "    tx = Transformer.from_crs(\"EPSG:4326\", f\"EPSG:{epsg}\", always_xy=True)\n",
    "    x1, y1 = tx.transform(bbox_ll[0], bbox_ll[1])\n",
    "    x2, y2 = tx.transform(bbox_ll[2], bbox_ll[3])\n",
    "    bounds_proj = (min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2))\n",
    "    return epsg, bbox_ll, bounds_proj\n",
    "\n",
    "def rasterio_env():\n",
    "    return rio.Env(\n",
    "        AWS_S3_ENDPOINT=os.environ[\"AWS_S3_ENDPOINT\"],\n",
    "        AWS_REGION=os.environ[\"AWS_REGION\"],\n",
    "        AWS_VIRTUAL_HOSTING=os.environ[\"AWS_VIRTUAL_HOSTING\"],\n",
    "        GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
    "        CPL_VSIL_CURL_ALLOWED_EXTENSIONS=\"tif,gtiff,jp2,xml\",\n",
    "    )\n",
    "\n",
    "# =========================================\n",
    "# AOI cloud filtering from SCL\n",
    "# =========================================\n",
    "SCL_CLOUD = [3, 7, 8, 9, 10, 11]\n",
    "\n",
    "def get_filtered_items_for_year(year, grid, bbox_ll, max_scene_cloud=80, aoi_cloud_thresh=0.5, min_coverage=0.1):\n",
    "    start_date = f\"{year}-{MONTH_START_END[0]}\"\n",
    "    end_date   = f\"{year}-{MONTH_START_END[1]}\"\n",
    "\n",
    "    print(f\"\\nüîé [{year}] STAC search in {grid} from {start_date} to {end_date}\")\n",
    "    items = search_s2_stac(start_date, end_date, grid, max_cloud_cover=max_scene_cloud)\n",
    "    items_s3 = prefer_s3_assets(items)\n",
    "\n",
    "    # Helper to get projected AOI bounds\n",
    "    def get_bounds_for_item(item):\n",
    "        try:\n",
    "            epsg, _, bounds_proj = detect_epsg_and_bounds([item], bbox_ll_override=bbox_ll)\n",
    "            return epsg, bounds_proj\n",
    "        except:\n",
    "            return None, None\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 1) Compute expected AOI size (in pixels) once per year\n",
    "    # -------------------------------------------------------\n",
    "    # Use the FIRST item to detect CRS for AOI projection\n",
    "    if len(items_s3) == 0:\n",
    "        return []\n",
    "\n",
    "    epsg_ref, aoi_bounds = get_bounds_for_item(items_s3[0])\n",
    "    if aoi_bounds is None:\n",
    "        return []\n",
    "\n",
    "    # AOI dimensions in meters\n",
    "    aoi_width  = aoi_bounds[2] - aoi_bounds[0]\n",
    "    aoi_height = aoi_bounds[3] - aoi_bounds[1]\n",
    "\n",
    "    # Expected pixel count at SCL resolution (20m)\n",
    "    expected_pixels = (aoi_width / 20) * (aoi_height / 20)\n",
    "\n",
    "    print(f\"üìê Expected AOI pixels (20m grid): {int(expected_pixels):,}\")\n",
    "\n",
    "    filtered_items = []\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 2) Process each scene individually\n",
    "    # -------------------------------------------------------\n",
    "    with rasterio_env():\n",
    "        for it in items_s3:\n",
    "\n",
    "            if \"SCL_20m\" not in it.assets:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                epsg_scene, bounds_proj = get_bounds_for_item(it)\n",
    "                if bounds_proj is None:\n",
    "                    continue\n",
    "\n",
    "                href = it.assets[\"SCL_20m\"].href\n",
    "                scl  = rioxarray.open_rasterio(href, masked=True, chunks={}).squeeze(\"band\", drop=True)\n",
    "                scl  = scl.rio.clip_box(*bounds_proj)\n",
    "\n",
    "                # If scene has NO data at all over AOI ‚Üí skip\n",
    "                if scl.isnull().all():\n",
    "                    print(f\"‚õî {it.id} ‚Üí No AOI coverage, skipped\")\n",
    "                    continue\n",
    "\n",
    "                # Count valid pixels\n",
    "                \n",
    "                valid_mask = (scl != 0) & scl.notnull() # scl pixels that are valid (neither nan nor 0(no data))\n",
    "                valid_pixels = valid_mask.sum().compute().item()\n",
    "\n",
    "                if valid_pixels == 0:\n",
    "                    print(f\"‚õî {it.id} ‚Üí AOI valid=0px, skipped\")\n",
    "                    continue\n",
    "\n",
    "                # Coverage ratio relative to expected AOI pixels\n",
    "                coverage_ratio = valid_pixels / expected_pixels\n",
    "\n",
    "                # Cloud ratio relative to valid AOI pixels\n",
    "                bad_pixels = (scl.isin(SCL_CLOUD) & valid_mask).sum().compute().item()\n",
    "                cloud_ratio = bad_pixels / valid_pixels\n",
    "\n",
    "                print(\n",
    "                    f\"üßÆ {it.id} ‚Üí clouds={cloud_ratio:.0%}, \"\n",
    "                    f\"coverage={coverage_ratio:.0%} \"\n",
    "                )\n",
    "\n",
    "                # Keep only if cloudiness low & coverage sufficient\n",
    "                if cloud_ratio <= aoi_cloud_thresh and coverage_ratio >= min_coverage:\n",
    "                    print(f\"   ‚úÖ kept\")\n",
    "                    filtered_items.append(it)\n",
    "                else:\n",
    "                    print(f\"   ‚õî skipped\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è {it.id} failed: {e}\")\n",
    "\n",
    "    return filtered_items\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# PROCESS YEAR FUNCTION\n",
    "# =========================================\n",
    "BAND_ORDER = [\"B02_10m\", \"B03_10m\", \"B04_10m\", \"B08_10m\", \"B11_20m\", \"B12_20m\"]\n",
    "BAND_LABELS = [\"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\"]\n",
    "SCL_BAD = [0,1,3,7,8,9,10,11]\n",
    "\n",
    "def process_year(year: int, grid: str, max_cloud: int, bbox_ll):\n",
    "    print(f\"\\n==== Year {year} | grid={grid} | clouds‚â§{max_cloud}% ====\")\n",
    "\n",
    "    # Get AOI-filtered items\n",
    "    items = get_filtered_items_for_year(year, GRID, bbox_ll, max_scene_cloud=80, aoi_cloud_thresh=0.5, min_coverage=0.1)\n",
    "    if not items:\n",
    "        print(\"  ‚ö†Ô∏è No AOI-clear items for this year; skipping.\")\n",
    "        return None\n",
    "\n",
    "    items_s3 = prefer_s3_assets(items)\n",
    "    epsg_out, bbox_ll_used, bounds_out = detect_epsg_and_bounds(items, bbox_ll_override=bbox_ll)\n",
    "    print(f\"  EPSG={epsg_out} | bbox_ll={bbox_ll_used} | bounds_proj={tuple(round(v,2) for v in bounds_out)}\")\n",
    "\n",
    "    bands_10m = [b for b in BAND_ORDER if b.endswith(\"10m\")]\n",
    "    bands_20m = [b for b in BAND_ORDER if b.endswith(\"20m\")]\n",
    "\n",
    "    stacks = []\n",
    "    ok, bad = 0, 0\n",
    "\n",
    "    with rasterio_env():\n",
    "        for it_s3 in items_s3:\n",
    "            try:\n",
    "                ref = None\n",
    "                pieces = []\n",
    "\n",
    "                # --- Read 10m bands ---\n",
    "                for bname in bands_10m:\n",
    "                    if bname not in it_s3.assets:\n",
    "                        continue\n",
    "                    da = rioxarray.open_rasterio(it_s3.assets[bname].href, masked=True, chunks={\"x\":1024,\"y\":1024}).squeeze(\"band\", drop=True)\n",
    "                    da = da.rio.clip_box(*bounds_out)\n",
    "                    if ref is None:\n",
    "                        ref = da\n",
    "                    pieces.append(da.expand_dims(\"band\"))\n",
    "\n",
    "                # --- Read and upsample 20m bands ---\n",
    "                for bname in bands_20m:\n",
    "                    if bname not in it_s3.assets:\n",
    "                        continue\n",
    "                    da20 = rioxarray.open_rasterio(it_s3.assets[bname].href, masked=True, chunks={\"x\":1024,\"y\":1024}).squeeze(\"band\", drop=True)\n",
    "                    da20 = da20.rio.clip_box(*bounds_out)\n",
    "                    da20u = da20.rio.reproject_match(ref, resampling=Resampling.bilinear)\n",
    "                    pieces.append(da20u.expand_dims(\"band\"))\n",
    "\n",
    "                if not pieces:\n",
    "                    continue\n",
    "\n",
    "                scene = xr.concat(pieces, dim=\"band\")\n",
    "                scene = scene.assign_coords(band=BAND_LABELS)\n",
    "\n",
    "                # --- SCL mask ---\n",
    "                scl_href = it_s3.assets.get(\"SCL_20m\")\n",
    "                if scl_href:\n",
    "                    scl = rioxarray.open_rasterio(scl_href.href, masked=True, chunks={}).squeeze(\"band\", drop=True).astype(\"uint16\")\n",
    "                    scl = scl.rio.clip_box(*bounds_out)\n",
    "                    scl = scl.rio.reproject_match(ref, resampling=Resampling.nearest)\n",
    "                    mask = ~scl.isin(SCL_BAD)\n",
    "                    scene = scene.where(mask)\n",
    "\n",
    "                stacks.append(scene.expand_dims(time=[np.datetime64(f\"{year}-07-15\")]))\n",
    "                ok += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è {it_s3.id} failed: {e}\")\n",
    "                bad += 1\n",
    "\n",
    "    if not stacks:\n",
    "        print(\"  ‚ö†Ô∏è No readable scenes; skipping year.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"  ‚úÖ Scenes OK: {ok} | failed: {bad}\")\n",
    "    arr = xr.concat(stacks, dim=\"time\")\n",
    "    arr = arr.where(arr > 0)\n",
    "\n",
    "    if REDUCER.lower() == \"median\":\n",
    "        red = arr.median(dim=\"time\", skipna=True)\n",
    "        red_tag = \"median\"\n",
    "    else:\n",
    "        #rgb_nir = [\"Blue\", \"Green\", \"Red\", \"NIR\"]\n",
    "        #swir = [\"SWIR1\", \"SWIR2\"]\n",
    "        #q25_rgbnir = arr.sel(band=rgb_nir).quantile(0.25, dim=\"time\", method=QUANT_METHOD, skipna=True)\n",
    "        #q75_swir = arr.sel(band=swir).quantile(0.75, dim=\"time\", method=QUANT_METHOD, skipna=True)\n",
    "        #red = xr.concat([q25_rgbnir, q75_swir], dim=\"band\").sel(band=BAND_LABELS)\n",
    "        red_tag = \"qmix25_75\"\n",
    "\n",
    "    out_dir = Path(OUT_DIR); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / f\"s2_{red_tag}_cc{MAX_CLOUD_COVER}_{year}_north_aoinan2.tif\"\n",
    "\n",
    "    red_u16 = (\n",
    "        red.fillna(0)\n",
    "        .clip(0, 10000)\n",
    "        .astype(\"uint16\")\n",
    "        .rio.write_nodata(0)\n",
    "        .rio.set_spatial_dims(\"x\", \"y\", inplace=False)\n",
    "        .rio.write_crs(f\"EPSG:{epsg_out}\", inplace=False)\n",
    "    )\n",
    "\n",
    "    print(f\" üìÇ Saving ‚Üí {out_path}\")\n",
    "    red_u16.transpose(\"band\", \"y\", \"x\").rio.to_raster(\n",
    "        out_path,\n",
    "        driver=\"GTiff\",\n",
    "        compress=\"deflate\",\n",
    "        tiled=True,\n",
    "        predictor=2,\n",
    "        BIGTIFF=\"IF_SAFER\",\n",
    "        blockxsize=512,\n",
    "        blockysize=512,\n",
    "        tags={f\"band_{i+1}\": name for i, name in enumerate(BAND_LABELS)},\n",
    "    )\n",
    "    return out_path\n",
    "\n",
    "# =========================================\n",
    "# RUN ALL YEARS\n",
    "# =========================================\n",
    "all_outputs = []\n",
    "for yr in YEARS:\n",
    "    p = process_year(yr, GRID, MAX_CLOUD_COVER, bbox_ll=BBOX_LL)\n",
    "    if p is not None:\n",
    "        all_outputs.append(str(p))\n",
    "\n",
    "print(\"\\nDone. Written files:\")\n",
    "for p in all_outputs:\n",
    "    print(\" ‚Ä¢\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df8afa",
   "metadata": {},
   "source": [
    "## Creating Annual aggregates (simpler scene version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67140af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# CONFIG\n",
    "# =========================================\n",
    "YEARS            = list(range(2017, 2025))     \n",
    "MONTH_START_END  = (\"07-01\", \"08-31\")          \n",
    "GRID             = \"MGRS-05WMU\"                     # e.g. \"MGRS-05WMN\"\n",
    "MAX_CLOUD_COVER  = 40                           \n",
    "BBOX_LL          = (-153.5, 70.5, -153, 71)         # (-154.25, 65.00, -154.00, 65.25)  # lon/lat bbox (minx,miny,maxx,maxy); set to None for full tile -153.5, 70.5, -153, 71\n",
    "\n",
    "# reducer: \"median\" or \"quantile\"\n",
    "REDUCER          = \"median\"                  # \"median\" or \"quantile\"\n",
    "Q                = 0.25                        # used only if REDUCER == \"quantile\"\n",
    "# quantile interpolation method: 'nearest', 'lower', 'higher', 'midpoint', or 'linear'\n",
    "QUANT_METHOD = \"nearest\"\n",
    "\n",
    "# output\n",
    "OUT_DIR          = \"CDSE_annual_median_small\"  \n",
    "\n",
    "# S3 endpoint setup\n",
    "import os\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]     = \"C364NPCJK6JQ64OIMZJR\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"...\" #!!! SET KEY\n",
    "os.environ[\"AWS_REGION\"]            = \"us-east-1\"\n",
    "os.environ[\"AWS_S3_ENDPOINT\"]       = \"eodata.dataspace.copernicus.eu\"\n",
    "os.environ[\"AWS_VIRTUAL_HOSTING\"]   = \"FALSE\"\n",
    "\n",
    "# =========================================\n",
    "# IMPORTS\n",
    "# =========================================\n",
    "from pathlib import Path\n",
    "from pystac_client import Client\n",
    "from pystac import Item\n",
    "import math\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from pyproj import Transformer\n",
    "import rasterio as rio\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "# =========================================\n",
    "# HELPERS\n",
    "# =========================================\n",
    "def search_s2_stac(start_date: str, end_date: str, grid: str, max_cloud_cover: int = 100) -> list[Item]:\n",
    "    cat = Client.open(\"https://stac.dataspace.copernicus.eu/v1/\")\n",
    "    search = cat.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        datetime=f\"{start_date}/{end_date}\",\n",
    "        query={\"eo:cloud_cover\": {\"lte\": max_cloud_cover}, \"grid:code\": {\"eq\": grid}},\n",
    "    )\n",
    "    items = list(search.items())\n",
    "    print(f\"  üîé Found {len(items)} items\")\n",
    "    return items\n",
    "\n",
    "def prefer_s3_assets(items):\n",
    "    out = []\n",
    "    for it in items:\n",
    "        it = it.clone()\n",
    "        for a in it.assets.values():\n",
    "            s3_href = None\n",
    "            extra = (getattr(a, \"extra_fields\", None) or {})\n",
    "            alt = extra.get(\"alternate\") or extra.get(\"alternates\")\n",
    "            if isinstance(alt, dict):\n",
    "                s3_href = (alt.get(\"s3\") or alt.get(\"S3\") or {}).get(\"href\")\n",
    "            elif isinstance(alt, list):\n",
    "                for d in alt:\n",
    "                    href = d.get(\"href\")\n",
    "                    if href and href.startswith(\"s3://\"):\n",
    "                        s3_href = href; break\n",
    "            if s3_href:\n",
    "                a.href = s3_href\n",
    "        out.append(it)\n",
    "    return out\n",
    "\n",
    "def detect_epsg_and_bounds(items, bbox_ll_override=None):\n",
    "    if not items:\n",
    "        raise ValueError(\"No items passed to detect_epsg_and_bounds\")\n",
    "\n",
    "    # bbox in lon/lat\n",
    "    if bbox_ll_override is None:\n",
    "        bbs = [it.bbox for it in items]\n",
    "        minx = min(b[0] for b in bbs); miny = min(b[1] for b in bbs)\n",
    "        maxx = max(b[2] for b in bbs); maxy = max(b[3] for b in bbs)\n",
    "        bbox_ll = (minx, miny, maxx, maxy)\n",
    "    else:\n",
    "        bbox_ll = bbox_ll_override\n",
    "\n",
    "    # EPSG from items (proj:epsg) else UTM guess\n",
    "    epsg = None\n",
    "    for it in items:\n",
    "        if \"proj:epsg\" in it.properties:\n",
    "            epsg = int(it.properties[\"proj:epsg\"]); break\n",
    "    if epsg is None:\n",
    "        lon, lat = ((bbox_ll[0] + bbox_ll[2]) / 2.0, (bbox_ll[1] + bbox_ll[3]) / 2.0)\n",
    "        zone = int(math.floor((lon + 180) / 6) + 1)\n",
    "        epsg = 32600 + zone if lat >= 0 else 32700 + zone\n",
    "\n",
    "    # reproject bbox to EPSG\n",
    "    tx = Transformer.from_crs(\"EPSG:4326\", f\"EPSG:{epsg}\", always_xy=True)\n",
    "    x1, y1 = tx.transform(bbox_ll[0], bbox_ll[1])\n",
    "    x2, y2 = tx.transform(bbox_ll[2], bbox_ll[3])\n",
    "    bounds_proj = (min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2))\n",
    "    return epsg, bbox_ll, bounds_proj\n",
    "\n",
    "def rasterio_env():\n",
    "    # Make GDAL/rasterio behave better on S3 (reduce directory scans)\n",
    "    return rio.Env(\n",
    "        AWS_S3_ENDPOINT=os.environ.get(\"AWS_S3_ENDPOINT\", \"eodata.dataspace.copernicus.eu\"),\n",
    "        AWS_REGION=os.environ.get(\"AWS_REGION\", \"us-east-1\"),\n",
    "        AWS_VIRTUAL_HOSTING=os.environ.get(\"AWS_VIRTUAL_HOSTING\", \"FALSE\"),\n",
    "        GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
    "        CPL_VSIL_CURL_ALLOWED_EXTENSIONS=\"tif,gtiff,jp2,xml\",\n",
    "    )\n",
    "# ================================================================================================================================================\n",
    "#PROCESS\n",
    "#=================================================================================================================================================\n",
    "# bands\n",
    "BAND_ORDER = [\"B02_10m\",\"B03_10m\",\"B04_10m\",\"B08_10m\",\"B11_20m\",\"B12_20m\"]\n",
    "BAND_LABELS = [\"Blue\",\"Green\",\"Red\",\"NIR\",\"SWIR1\",\"SWIR2\"]\n",
    "SCL_BAD = [0,1,3,7,8,9,10,11]  # S2 SCL classes to mask\n",
    "\n",
    "def process_year(year: int, grid: str, max_cloud: int, bbox_ll):\n",
    "    print(f\"\\n==== Year {year} | grid={grid} | clouds‚â§{max_cloud}% ====\")\n",
    "    start_date = f\"{year}-{MONTH_START_END[0]}\"\n",
    "    end_date   = f\"{year}-{MONTH_START_END[1]}\"\n",
    "\n",
    "    # 1) STAC search\n",
    "    items = search_s2_stac(start_date, end_date, grid, max_cloud_cover=max_cloud)\n",
    "    if not items:\n",
    "        print(\"  ‚ö†Ô∏è No items for this year; skipping.\")\n",
    "        return None\n",
    "\n",
    "    # 2) Prefer S3 asset hrefs\n",
    "    items_s3 = prefer_s3_assets(items)\n",
    "\n",
    "    # 3) Bounds & EPSG (use bbox)\n",
    "    epsg_out, bbox_ll_used, bounds_out = detect_epsg_and_bounds(items, bbox_ll_override=bbox_ll)\n",
    "    print(f\"  EPSG={epsg_out} | bbox_ll={bbox_ll_used} | bounds_proj={tuple(round(v,2) for v in bounds_out)}\")\n",
    "\n",
    "    # Split bands\n",
    "    bands_10m = [b for b in BAND_ORDER if b.endswith(\"10m\")]\n",
    "    bands_20m = [b for b in BAND_ORDER if b.endswith(\"20m\")]\n",
    "\n",
    "    stacks = []\n",
    "    ok, bad = 0, 0\n",
    "\n",
    "    with rasterio_env():\n",
    "        for it_s3, it_orig in zip(items_s3, items):\n",
    "            try:\n",
    "                # --- read 10m bands ---\n",
    "                ref = None\n",
    "                pieces = []\n",
    "                for bname in bands_10m:\n",
    "                    if bname not in it_s3.assets:\n",
    "                        continue\n",
    "                    href = it_s3.assets[bname].href  # <-- S3 href\n",
    "                    da = rioxarray.open_rasterio(href, masked=True, chunks={\"x\":1024,\"y\":1024}).squeeze(\"band\", drop=True)\n",
    "                    da = da.rio.clip_box(*bounds_out)  # bounds are in EPSG of the tile\n",
    "                    if ref is None:\n",
    "                        ref = da\n",
    "                    pieces.append(da.expand_dims(\"band\"))\n",
    "\n",
    "                # --- read & upsample 20m bands ---\n",
    "                for bname in bands_20m:\n",
    "                    if bname not in it_s3.assets:\n",
    "                        continue\n",
    "                    href = it_s3.assets[bname].href\n",
    "                    da20 = rioxarray.open_rasterio(href, masked=True, chunks={\"x\":1024,\"y\":1024}).squeeze(\"band\", drop=True)\n",
    "                    da20 = da20.rio.clip_box(*bounds_out)\n",
    "                    if ref is None:\n",
    "                        ref = da20\n",
    "                    da20u = da20.rio.reproject_match(ref, resampling=Resampling.bilinear)\n",
    "                    pieces.append(da20u.expand_dims(\"band\"))\n",
    "\n",
    "                if not pieces:\n",
    "                    continue\n",
    "\n",
    "                # --- combine into single scene ---\n",
    "                scene = xr.concat(pieces, dim=\"band\")  \n",
    "                if scene.sizes[\"band\"] != len(BAND_LABELS):\n",
    "                    print(f\"  ‚ö†Ô∏è Szene hat unerwartete Bandanzahl ({scene.sizes['band']}); wird √ºbersprungen.\")\n",
    "                    continue              \n",
    "                have_names = []\n",
    "                for b in BAND_ORDER:\n",
    "                    have_names.append(b)\n",
    "\n",
    "\n",
    "                # --- SCL mask ---\n",
    "                if \"_20m\" in it_s3.assets:\n",
    "                    scl_href = it_s3.assets[\"SCL_20m\"].href\n",
    "                    scl = rioxarray.open_rasterio(scl_href, masked=True, chunks={\"x\":1024,\"y\":1024}).squeeze(\"band\", drop=True).astype(\"uint16\")\n",
    "                    scl = scl.rio.clip_box(*bounds_out)\n",
    "                    scl = scl.rio.reproject_match(ref, resampling=Resampling.nearest)\n",
    "                    mask = ~scl.isin(SCL_BAD)\n",
    "\n",
    "                #----------outlier mask / brightness mask------------------------------------------------------------------------------------\n",
    "\n",
    "                scene = scene.where(mask)\n",
    "                scene = scene.assign_coords(band=BAND_LABELS)\n",
    "                # --- Brightness mask (exclude very bright RGB pixels) ---\n",
    "                # NOTE: Sentinel-2 reflectance values are scaled 0‚Äì10000, so threshold=0.12 -> 1200\n",
    "                BRIGHT_THRESHOLD = 2100  \n",
    "\n",
    "                # Select RGB bands\n",
    "                rgb = scene.sel(band=[\"Red\", \"Green\", \"Blue\"])\n",
    "\n",
    "                # Compute a combined mask: True where NOT bright (keep these)\n",
    "                bright_mask = ~((rgb.sel(band=\"Red\")   > BRIGHT_THRESHOLD) &\n",
    "                                (rgb.sel(band=\"Green\") > BRIGHT_THRESHOLD) &\n",
    "                                (rgb.sel(band=\"Blue\")  > BRIGHT_THRESHOLD))\n",
    "\n",
    "                # Apply to all bands\n",
    "                scene = scene.where(bright_mask)\n",
    "\n",
    "\n",
    "                # --- per-scene outlier mask (2œÉ) ---\n",
    "                scene_mean = scene.mean(dim=(\"y\", \"x\"), skipna=True)\n",
    "                scene_std  = scene.std(dim=(\"y\", \"x\"), skipna=True)\n",
    "\n",
    "                # reshape \n",
    "                scene_mean = scene_mean.expand_dims({\"y\": scene.sizes[\"y\"], \"x\": scene.sizes[\"x\"]})\n",
    "                scene_std  = scene_std.expand_dims({\"y\": scene.sizes[\"y\"], \"x\": scene.sizes[\"x\"]})\n",
    "\n",
    "\n",
    "                lower = scene_mean - 3 * scene_std\n",
    "                upper = scene_mean + 3 * scene_std\n",
    "                scene_mask = (scene >= lower) & (scene <= upper)\n",
    "                scene = scene.where(scene_mask)\n",
    "\n",
    "                print(f\"    ‚Ü™ Outlier-masked pixels in scene:\") #  {(~scene_mask).sum().compute().item():,}\")\n",
    "\n",
    "            #---------------------------------------------------------------------------------------------------\n",
    "                stacks.append(scene.expand_dims(time=[np.datetime64(f\"{year}-07-15\")]))\n",
    "                ok += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è {it_orig.id} failed: {e}\")\n",
    "                bad += 1\n",
    "\n",
    "    if not stacks:\n",
    "        print(\"  ‚ö†Ô∏è No readable scenes; skipping year.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"  ‚úÖ Scenes OK: {ok} | failed: {bad}\")\n",
    "    arr = xr.concat(stacks, dim=\"time\")\n",
    "    arr = arr.where(arr > 0)\n",
    "\n",
    "    # ===== REDUCTION (median or quantile) =====\n",
    "    if REDUCER.lower() == \"median\":                     # mean ausrobieren / keine maske und nur 25 % quantil\n",
    "        red = arr.median(dim=\"time\", skipna=True)\n",
    "        red_tag = \"median\"\n",
    "    else:\n",
    "        # Make sure bands are labeled (should already be from above)\n",
    "        if \"band\" not in arr.coords or set(arr.band.values) != set(BAND_LABELS):\n",
    "            arr = arr.assign_coords(band=BAND_LABELS)\n",
    "\n",
    "        # Define band groups\n",
    "        rgb_nir = [\"Blue\", \"Green\", \"Red\", \"NIR\"]\n",
    "        swir    = [\"SWIR1\", \"SWIR2\"]\n",
    "\n",
    "        # Compute per-group quantiles with your chosen method\n",
    "        q25_rgbnir = arr.sel(band=rgb_nir).quantile(0.25, dim=\"time\", method=QUANT_METHOD, skipna=True)\n",
    "        q75_swir   = arr.sel(band=swir).quantile(0.75, dim=\"time\", method=QUANT_METHOD, skipna=True)\n",
    "\n",
    "        # Stitch back together and restore canonical band order\n",
    "        red = xr.concat([q25_rgbnir, q75_swir], dim=\"band\").sel(band=BAND_LABELS)\n",
    "\n",
    "        red_tag = \"qmix25_75\"             \n",
    "\n",
    "\n",
    "    # ===== SAVE RASTER =====\n",
    "    out_dir = Path(OUT_DIR); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / f\"s2_{red_tag}_cc{MAX_CLOUD_COVER}_{year}_north_outbright2100.tif\"\n",
    "\n",
    "\n",
    "    red_u16 = (\n",
    "        red.fillna(0)\n",
    "        .clip(0, 10000)\n",
    "        .astype(\"uint16\")\n",
    "        .rio.write_nodata(0)\n",
    "        .rio.set_spatial_dims(\"x\",\"y\", inplace=False)\n",
    "        .rio.write_crs(f\"EPSG:{epsg_out}\", inplace=False)\n",
    "        )\n",
    "\n",
    "    red_u16 = red_u16.assign_coords(band=BAND_LABELS)\n",
    "\n",
    "\n",
    "    print(f\" üìÇ Saving ‚Üí {out_path}\")\n",
    "    red_u16.transpose(\"band\",\"y\",\"x\").rio.to_raster(\n",
    "        out_path,\n",
    "        driver=\"GTiff\",\n",
    "        compress=\"deflate\",\n",
    "        tiled=True,\n",
    "        predictor=2,\n",
    "        BIGTIFF=\"IF_SAFER\",\n",
    "        blockxsize=512,\n",
    "        blockysize=512,\n",
    "        tags={f\"band_{i+1}\": name for i, name in enumerate(BAND_LABELS)},\n",
    "        )\n",
    "    return out_path\n",
    "\n",
    "# =========================================\n",
    "# RUN ALL YEARS\n",
    "# =========================================\n",
    "all_outputs = []\n",
    "for yr in YEARS:\n",
    "    p = process_year(yr, GRID, MAX_CLOUD_COVER, bbox_ll=BBOX_LL)\n",
    "    if p is not None:\n",
    "        all_outputs.append(str(p))\n",
    "\n",
    "print(\"\\nDone. Written files:\")\n",
    "for p in all_outputs:\n",
    "    print(\" ‚Ä¢\", p)\n",
    "\n",
    "#cc: 30: 8, 4, 8, 16, 7, 12, 13, 5 = 50min mit outlier mask\n",
    "#cc 40: 11, 10, 9, 18, 13, 14, 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73515b1b",
   "metadata": {},
   "source": [
    "## Calculating TC images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === tasseled_cap_mosaic_generation.py ===\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from dask.diagnostics import ProgressBar\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*coordinate precision.*\")\n",
    "\n",
    "median_dir = Path(\"CDSE_annual_median_small\")       \n",
    "tc_dir = Path(\"CDSE_tc_small\")                      \n",
    "tc_dir.mkdir(exist_ok=True)\n",
    "years = list(range(2018, 2025))\n",
    "\n",
    "# Sentinel-2 Tasseled Cap coefficients \n",
    "coeffs = {\n",
    "    \"tcb\": dict(Blue=0.3037, Green=0.2793, Red=0.4743, NIR=0.5585, SWIR1=0.5082, SWIR2=0.1863),\n",
    "    \"tcg\": dict(Blue=-0.2848, Green=-0.2435, Red=-0.5436, NIR=0.7243, SWIR1=0.0840, SWIR2=-0.1800),\n",
    "    \"tcw\": dict(Blue=0.1509, Green=0.1973, Red=0.3279, NIR=0.3406, SWIR1=-0.7112, SWIR2=-0.4572),\n",
    "}\n",
    "\n",
    "for year in years:\n",
    "    in_file = median_dir / f\"s2_median_cc30_{year}_north_outbright1800.tif\"\n",
    "    out_file = tc_dir / f\"tc_median_c30_{year}_north_outbright1800_std3.tif\"\n",
    "\n",
    "    if not in_file.exists():\n",
    "        print(f\"‚ùå Missing median mosaic for {year}\")\n",
    "        continue\n",
    "    if out_file.exists():\n",
    "        print(f\"‚è≠Ô∏è Already exists, skipping {out_file}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‚úÖ Loading: {in_file}\")\n",
    "    # Important: masked=True makes rioxarray treat nodata (0) as NaN\n",
    "    da = rioxarray.open_rasterio(in_file, chunks={\"x\": 1024, \"y\": 1024}, masked=True)\n",
    "\n",
    "    # assign band names, convert reflectance to 0‚Äì1\n",
    "    da = da.assign_coords(band=[\"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\"]).astype(\"float32\") / 10000.0          # not needed - 0.1 \n",
    "\n",
    "    # Ensure true zeros are NaN (in case old medians used fillna(0))\n",
    "    da = da.where(da != 0)\n",
    "\n",
    "    # Split bands\n",
    "    blue, green, red, nir, swir1, swir2 = da.sel(band=[\"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\"])\n",
    "\n",
    "    def tc(c):\n",
    "        return (c[\"Blue\"]*blue + c[\"Green\"]*green + c[\"Red\"]*red +\n",
    "                c[\"NIR\"]*nir + c[\"SWIR1\"]*swir1 + c[\"SWIR2\"]*swir2)\n",
    "\n",
    "    # Compute tasseled cap \n",
    "    tcb = tc(coeffs[\"tcb\"])\n",
    "    tcg = tc(coeffs[\"tcg\"])\n",
    "    tcw = tc(coeffs[\"tcw\"])\n",
    "\n",
    "    # Stack tc\n",
    "    tc_stack = xr.concat([tcb, tcg, tcw], dim=\"band\")\n",
    "    tc_stack = tc_stack.assign_coords(band=[\"TCB\", \"TCG\", \"TCW\"])\n",
    "    tc_stack = tc_stack.rio.write_crs(da.rio.crs)\n",
    "\n",
    "    # Ensure NaNs are preserved\n",
    "    tc_stack = tc_stack.astype(\"float32\").rio.write_nodata(np.nan)\n",
    "\n",
    "    print(f\"üíæ Saving tasseled cap mosaic: {out_file}\")\n",
    "    with ProgressBar():\n",
    "        (\n",
    "            tc_stack.compute(scheduler=\"threads\")\n",
    "            .transpose(\"band\", \"y\", \"x\")\n",
    "            .rio.to_raster(\n",
    "                out_file,\n",
    "                driver=\"GTiff\",\n",
    "                tiled=True,\n",
    "                compress=\"deflate\",\n",
    "                BIGTIFF=\"IF_SAFER\",\n",
    "                predictor=3,           \n",
    "                blockxsize=1024,\n",
    "                blockysize=1024,\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ All tasseled cap mosaics saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b02b4e",
   "metadata": {},
   "source": [
    "## Trend Calculation (fixed vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# TREND CALCULATION FOR TC STACKS\n",
    "# =========================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from dask.diagnostics import ProgressBar\n",
    "import dask\n",
    "import logging\n",
    "\n",
    "# -----------------------------------------\n",
    "# CONFIG\n",
    "# -----------------------------------------\n",
    "tc_dir     = Path(\"CDSE_tc_small\")          # input mosaics\n",
    "trend_dir  = Path(\"CDSE_tc_trend_results\")  # output directory\n",
    "trend_dir.mkdir(exist_ok=True)\n",
    "\n",
    "years = list(range(2017, 2025))\n",
    "bands_tc = [\"TCB\", \"TCG\", \"TCW\"]\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1. LOAD ALL TASSELED CAP MOSAICS\n",
    "# -----------------------------------------\n",
    "arrays = []\n",
    "\n",
    "for year in years:\n",
    "    fp = tc_dir / f\"tc_median_c30_{year}_north_outbright1800_std3.tif\"\n",
    "    if not fp.exists():\n",
    "        print(f\"‚ùå Missing {fp}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‚úÖ Loading {fp}\")\n",
    "    da = rioxarray.open_rasterio(fp, chunks={\"x\": 1024, \"y\": 1024})\n",
    "\n",
    "    # Assign TC band names\n",
    "    da = da.assign_coords(band=bands_tc)\n",
    "\n",
    "    # Add numeric time coordinate\n",
    "    da = da.expand_dims(time=[np.datetime64(f\"{year}-07-15\")])\n",
    "\n",
    "    arrays.append(da)\n",
    "\n",
    "if not arrays:\n",
    "    raise RuntimeError(\"No tasseled cap mosaics found!\")\n",
    "\n",
    "# Concatenate stack\n",
    "stack = xr.concat(arrays, dim=\"time\").transpose(\"time\", \"band\", \"y\", \"x\")\n",
    "stack = stack.chunk({\"time\": -1, \"x\": 1024, \"y\": 1024})\n",
    "stack.name = \"tc\"\n",
    "\n",
    "print(f\"üß© Stack shape: {stack.shape} (time, band, y, x)\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2. FIX THE TIME AXIS FOR REGRESSION\n",
    "# -----------------------------------------\n",
    "# Convert datetime64 ‚Üí integer years\n",
    "years_numeric = stack[\"time\"].dt.year\n",
    "\n",
    "# Replace time dim with 'year'\n",
    "stack = stack.assign_coords(year=(\"time\", years_numeric.data))\n",
    "stack = stack.swap_dims({\"time\": \"year\"})\n",
    "\n",
    "print(f\"üìÖ Using year values for regression: {list(years_numeric.values)}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3. TREND REGRESSION (PER YEAR)\n",
    "# -----------------------------------------\n",
    "results = []\n",
    "\n",
    "for band in bands_tc:\n",
    "    print(f\"üìà Computing trend for {band}...\")\n",
    "\n",
    "    sub = stack.sel(band=band)\n",
    "\n",
    "    # Fit a first-degree polynomial across the 'year' axis\n",
    "    fit = sub.to_dataset(name=\"tc\").polyfit(dim=\"year\", deg=1)\n",
    "\n",
    "    # Extract slope (degree 1 coefficient)\n",
    "    slope = fit[\"tc_polyfit_coefficients\"].sel(degree=1)\n",
    "\n",
    "    # OPTIONAL ‚Äî\n",
    "    # match GEE visualization intensity (your GEE script did \"*10\")\n",
    "    slope = slope * 10\n",
    "\n",
    "    slope = slope.expand_dims(band=[f\"{band}_slope\"])\n",
    "    results.append(slope)\n",
    "\n",
    "# Combine all slope bands\n",
    "trend = xr.concat(results, dim=\"band\")\n",
    "trend.rio.write_crs(stack.rio.crs, inplace=True)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4. COMPUTE THE ARRAY\n",
    "# -----------------------------------------\n",
    "out_path = trend_dir / \"tc_trend_small_fixed_outbrightness.tif\"\n",
    "print(f\"üíæ Saving trend raster: {out_path}\")\n",
    "\n",
    "# Threaded Dask scheduler\n",
    "dask.config.set(scheduler=\"threads\")\n",
    "logging.getLogger(\"tornado.application\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"tornado.general\").setLevel(logging.ERROR)\n",
    "\n",
    "with ProgressBar(dt=30.0):  \n",
    "    trend = trend.compute()\n",
    "\n",
    "trend_vis = trend.clip(-0.3, 0.3)\n",
    "trend_vis = ((trend_vis + 0.3) / 0.6 * 255).astype(\"uint8\")\n",
    "trend_vis.transpose(\"band\", \"y\", \"x\").rio.to_raster(\"trend_visual.tif\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5. SAVE TO GEOTIFF\n",
    "# -----------------------------------------\n",
    "trend_vis.transpose(\"band\", \"y\", \"x\").rio.to_raster(\n",
    "    out_path,\n",
    "    driver=\"GTiff\",\n",
    "    tiled=True,\n",
    "    compress=\"deflate\",\n",
    "    BIGTIFF=\"IF_SAFER\",\n",
    "    predictor=2,\n",
    "    blockxsize=1024,\n",
    "    blockysize=1024,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trend image saved successfully.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
